%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                   %%
%%    Thesis and Term Paper Template                                 %%
%%    Created by Annemarie Friedrich                                 %%
%%                                                                   %%
%%    Original available from:                                       %%
%%    http://www.coli.uni-saarland.de/~afried/files/Term%20Paper.zip %%
%%                                                                   %%
%%    This header added by Dave Howcroft for the version at:         %%
%%    https://repos.lsv.uni-saarland.de/howcroft/texplates           %%
%%                                                                   %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[pdftex,12pt,a4paper]{article}

% Lorem ipsum filler text for the template
\usepackage{lipsum}

% For graphics
\usepackage[pdftex]{graphicx}
% Enables placing a figure at the position where it occurs in the text 
% by using [H]
\usepackage{here}

% For flexible tables
\usepackage{multirow}

% Set the encoding to UTF-8
\usepackage[utf8]{inputenc}

% Sophisticated citation.
% Check out: http://merkel.zoneo.net/Latex/natbib.php
\usepackage{natbib}

% Math symbols not defined in the usual package, e.g. arrows that are crossed.
\usepackage{amssymb}

% Arrows with text / superscript
\usepackage{amsmath}

% Different font - something like Arial
%\usepackage{mathptmx}

% Adjust margin of paper.
\usepackage{geometry}
\geometry{a4paper, top=25mm, left=25mm, right=25mm, bottom=25mm}

% Zeilenabstand 1.25 %
\linespread{1.2}

% Example Environments
\usepackage{amsthm}
\newtheoremstyle{style}   
  {0.5cm}              %Space above    
  {-0.8cm}              %Space below
  {}                      %Body font: original {\normalfont}    
  {}                      %Indent amount (empty = no indent,%\parindent = paraindent)    
  {\normalfont\bfseries}  %Thm head font original       
  {{\normalfont\bfseries \thmname{#1}\thmnumber{ #2}}}
\theoremstyle{style}
\newtheorem{example}{Example}[section]

% Formula Environments
\newtheorem{formula}{Formula}[section]

% Computational Linguistics trees etc.
\usepackage{xyling}

% Nicer captions
\usepackage{caption2}
\newcaptionstyle{mystyle}{%
  \normalcaptionparams
  \renewcommand\captionlabelfont{\bfseries}%
  \renewcommand\captionlabeldelim{.}%
  \onelinecaptionsfalse
  \usecaptionstyle{centerlast}}

\captionstyle{mystyle}

% Table of contents depth
\setcounter{tocdepth}{3}

% A horizontal rule for the title page
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

% Paragraph and indent (as required by Prof. Dr. Pinkal)
\setlength{\parindent}{0pt}
\setlength{\parskip}{2ex plus 0.5ex minus 0.2ex}

\begin{document}

% Include the title page (modify title.tex!)
\input{title.tex}

\thispagestyle{empty}
\begin{abstract}

Transfer learning has become widely popular learning technique in many applications specifically in a natural language processing setting. There can be many ways to transfer the knowledge from one setting to another. In this report, the popular technique of building pre-trained transfer models and its performance of downstream task is discussed in detail. \\
This type of transfer learning involves two steps, First is to train a machine learning model on a data rich task. Here, data rich task refers to the task for which data is easily available such as language modelling where the data can be simply scraped from the web pages which are abundantly available. This model called the pretrained model captures the low-level details of the task such as semantics or grammar of the language. Second step involves reusing this general-purpose knowledge gained by fine tuning the pretrained model on specific NLP tasks such as named entity recognition or sentiment classification task.\\ 
The paper “Exploring the limits of transfer learning with text-to-text transformer” extends this idea into a text-in, text out model that can be used across many NLP tasks. It also presents a detailed comparative study of different transfer learning techniques and incorporates the best performing methods to present the final model T5 along with the C4 dataset that was used to train it. Together it achieves state of the art performance at the time of its release on many NLP tasks. 


\end{abstract}
\newpage

% Table of contents
\thispagestyle{empty}
\tableofcontents

\newpage

% Start of content
\setcounter{page}{1}		% Seitenzähler auf 1 setzen %
%\pagestyle{fancy}				% fancy header style
\pagenumbering{arabic}
\newpage
\input{section1}

\newpage
\input{section2}

\newpage
\input{section3}


% REFERENCES
\newpage

\bibliographystyle{apalike}

\bibliography{references}
\cite{raffel2020exploring}
\cite{NIPS2017_7181}
\cite{devlin-etal-2019-bert}
\cite{JayAlammar.2018}
\cite{Google_AI_blog.2020}
\end{document}